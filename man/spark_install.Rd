% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/install_spark.R, R/install_spark_versions.R
\name{spark_install}
\alias{spark_install}
\alias{spark_uninstall}
\alias{spark_install_dir}
\alias{spark_install_tar}
\alias{spark_installed_versions}
\alias{spark_available_versions}
\title{Download and install various versions of Spark}
\usage{
spark_install(
  version = NULL,
  hadoop_version = NULL,
  reset = TRUE,
  logging = "INFO",
  verbose = interactive()
)

spark_uninstall(version, hadoop_version)

spark_install_dir()

spark_install_tar(tarfile)

spark_installed_versions()

spark_available_versions(
  show_hadoop = FALSE,
  show_minor = FALSE,
  show_future = FALSE
)
}
\arguments{
\item{version}{Version of Spark to install. See \code{spark_available_versions} for a list of supported versions}

\item{hadoop_version}{Version of Hadoop to install. See \code{spark_available_versions} for a list of supported versions}

\item{reset}{Attempts to reset settings to defaults.}

\item{logging}{Logging level to configure install. Supported options: "WARN", "INFO"}

\item{verbose}{Report information as Spark is downloaded / installed}

\item{tarfile}{Path to TAR file conforming to the pattern spark-###-bin-(hadoop)?### where ###
reference spark and hadoop versions respectively.}

\item{show_hadoop}{Show Hadoop distributions?}

\item{show_minor}{Show minor Spark versions?}

\item{show_future}{Should future versions which have not been released be shown?}
}
\value{
List with information about the installed version.
}
\description{
Install versions of Spark for use with local Spark connections
  (i.e. \code{spark_connect(master = "local"})
}
