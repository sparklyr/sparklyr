---
title: "Spark ML -- Bisecting K-Means Clustering"
aliases:
  - reference/sparklyr/latest/ml_bisecting_kmeans
---

    <div class="doc-page">

    <div class="doc-page-index">
    <ul data-gumshoe>
    <li><a href="#arguments">Arguments</a></li>
    
    <li><a href="#value">Value</a></li>

    <li><a href="#see-also">See also</a></li>
        </ul>
    </div>

    <div class="doc-page-body">

    
    <p>A bisecting k-means algorithm based on the paper "A comparison of document clustering techniques" by Steinbach, Karypis, and Kumar, with modification to fit Spark. The algorithm starts from a single cluster that contains all points. Iteratively it finds divisible clusters on the bottom level and bisects each of them using k-means, until there are k leaf clusters in total or no leaf clusters are divisible. The bisecting steps of clusters on the same level are grouped together to increase parallelism. If bisecting all divisible clusters on the bottom level would result more than k leaf clusters, larger clusters get higher priority.</p>
    

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>ml_bisecting_kmeans</span>(<span class='no'>x</span>, <span class='kw'>formula</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>k</span> <span class='kw'>=</span> <span class='fl'>4L</span>, <span class='kw'>max_iter</span> <span class='kw'>=</span> <span class='fl'>20L</span>,
  <span class='kw'>seed</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>min_divisible_cluster_size</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>features_col</span> <span class='kw'>=</span> <span class='st'>"features"</span>,
  <span class='kw'>prediction_col</span> <span class='kw'>=</span> <span class='st'>"prediction"</span>,
  <span class='kw'>uid</span> <span class='kw'>=</span> <span class='fu'><a href='random_string'>random_string</a></span>(<span class='st'>"bisecting_bisecting_kmeans_"</span>), <span class='no'>...</span>)</code></pre></div>
    
    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">

    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>

    <tr>
      <td>x</td>
      <td><p>A <code>spark_connection</code>, <code>ml_pipeline</code>, or a <code>tbl_spark</code>.</p></td>
    </tr>
    <tr>
      <td>formula</td>
      <td><p>Used when <code>x</code> is a <code>tbl_spark</code>. R formula as a character string or a formula. This is used to transform the input dataframe before fitting, see <a href='ft_r_formula'>ft_r_formula</a> for details.</p></td>
    </tr>
    <tr>
      <td>k</td>
      <td><p>The number of clusters to create</p></td>
    </tr>
    <tr>
      <td>max_iter</td>
      <td><p>The maximum number of iterations to use.</p></td>
    </tr>
    <tr>
      <td>seed</td>
      <td><p>A random seed. Set this value if you need your results to be
reproducible across repeated calls.</p></td>
    </tr>
    <tr>
      <td>min_divisible_cluster_size</td>
      <td><p>The minimum number of points (if greater than or equal to 1.0) or the minimum proportion of points (if less than 1.0) of a divisible cluster (default: 1.0).</p></td>
    </tr>
    <tr>
      <td>features_col</td>
      <td><p>Features column name, as a length-one character vector. The column should be single vector column of numeric values. Usually this column is output by <code><a href='ft_r_formula'>ft_r_formula</a></code>.</p></td>
    </tr>
    <tr>
      <td>prediction_col</td>
      <td><p>Prediction column name.</p></td>
    </tr>
    <tr>
      <td>uid</td>
      <td><p>A character string used to uniquely identify the ML estimator.</p></td>
    </tr>
    <tr>
      <td>...</td>
      <td><p>Optional arguments; currently unused.</p></td>
    </tr>
    </table>
    
    <h2 id="value">Value</h2>

    <p>The object returned depends on the class of <code>x</code>.</p><ul>
<li><p><code>spark_connection</code>: When <code>x</code> is a <code>spark_connection</code>, the function returns an instance of a <code>ml_estimator</code> object. The object contains a pointer to
  a Spark <code>Estimator</code> object and can be used to compose
  <code>Pipeline</code> objects.</p></li>
<li><p><code>ml_pipeline</code>: When <code>x</code> is a <code>ml_pipeline</code>, the function returns a <code>ml_pipeline</code> with
  the clustering estimator appended to the pipeline.</p></li>
<li><p><code>tbl_spark</code>: When <code>x</code> is a <code>tbl_spark</code>, an estimator is constructed then
  immediately fit with the input <code>tbl_spark</code>, returning a clustering model.</p></li>
<li><p><code>tbl_spark</code>, with <code>formula</code> or <code>features</code> specified: When <code>formula</code>
    is specified, the input <code>tbl_spark</code> is first transformed using a
    <code>RFormula</code> transformer before being fit by
    the estimator. The object returned in this case is a <code>ml_model</code> which is a
    wrapper of a <code>ml_pipeline_model</code>. This signature does not apply to <code><a href='ml_lda'>ml_lda()</a></code>.</p></li>
</ul>

    
    <h2 id="see-also">See also</h2>

    <p>See <a href='http://spark.apache.org/docs/latest/ml-clustering'>http://spark.apache.org/docs/latest/ml-clustering</a> for
  more information on the set of clustering algorithms.</p>
<p>Other ml clustering algorithms: <code><a href='ml_gaussian_mixture'>ml_gaussian_mixture</a></code>,
  <code><a href='ml_kmeans'>ml_kmeans</a></code>, <code><a href='ml_lda'>ml_lda</a></code></p>
    

    </div>

    </div>

