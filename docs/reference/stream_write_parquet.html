---
title: "Write Parquet Stream"
aliases:
  - reference/sparklyr/latest/stream_write_parquet.html
---

    <div>

    <div>
    <ul data-gumshoe>
    <li><a href="#arguments">Arguments</a></li>
    <li><a href="#see-also">See also</a></li>
    <li><a href="#examples">Examples</a></li>
    </ul>
    </div>

    <div>

    <p>Writes a Spark dataframe stream into a parquet stream.</p>

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>stream_write_parquet</span>(<span class='no'>x</span>, <span class='no'>path</span>, <span class='kw'>mode</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"append"</span>, <span class='st'>"complete"</span>, <span class='st'>"update"</span>),
  <span class='kw'>trigger</span> <span class='kw'>=</span> <span class='fu'><a href='stream_trigger_interval.html'>stream_trigger_interval</a></span>(), <span class='kw'>checkpoint</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span>(<span class='no'>path</span>,
  <span class='st'>"checkpoints"</span>, <span class='fu'><a href='random_string.html'>random_string</a></span>(<span class='st'>""</span>)), <span class='kw'>options</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(), <span class='no'>...</span>)</code></pre></div>

    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">

    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>

    <tr>
      <td>x</td>
      <td><p>A Spark DataFrame or dplyr operation</p></td>
    </tr>
    <tr>
      <td>path</td>
      <td><p>The destination path. Needs to be accessible from the cluster.
Supports the <samp>"hdfs://"</samp>, <samp>"s3a://"</samp> and <samp>"file://"</samp> protocols.</p></td>
    </tr>
    <tr>
      <td>mode</td>
      <td><p>Specifies how data is written to a streaming sink. Valid values are
<code>"append"</code>, <code>"complete"</code> or <code>"update"</code>.</p></td>
    </tr>
    <tr>
      <td>trigger</td>
      <td><p>The trigger for the stream query, defaults to micro-batches runnnig
every 5 seconds. See <code><a href='stream_trigger_interval.html'>stream_trigger_interval</a></code> and
<code><a href='stream_trigger_continuous.html'>stream_trigger_continuous</a></code>.</p></td>
    </tr>
    <tr>
      <td>checkpoint</td>
      <td><p>The location where the system will write all the checkpoint
information to guarantee end-to-end fault-tolerance.</p></td>
    </tr>
    <tr>
      <td>options</td>
      <td><p>A list of strings with additional options.</p></td>
    </tr>
    <tr>
      <td>...</td>
      <td><p>Optional arguments; currently unused.</p></td>
    </tr>
    </table>

    <h2 id="see-also">See also</h2>

    <div class='dont-index'><p>Other Spark stream serialization: <code><a href='stream_read_csv.html'>stream_read_csv</a></code>,
  <code><a href='stream_read_json.html'>stream_read_json</a></code>,
  <code><a href='stream_read_kafka.html'>stream_read_kafka</a></code>,
  <code><a href='stream_read_orc.html'>stream_read_orc</a></code>,
  <code><a href='stream_read_parquet.html'>stream_read_parquet</a></code>,
  <code><a href='stream_read_scoket.html'>stream_read_scoket</a></code>,
  <code><a href='stream_read_text.html'>stream_read_text</a></code>,
  <code><a href='stream_write_console.html'>stream_write_console</a></code>,
  <code><a href='stream_write_csv.html'>stream_write_csv</a></code>,
  <code><a href='stream_write_json.html'>stream_write_json</a></code>,
  <code><a href='stream_write_kafka.html'>stream_write_kafka</a></code>,
  <code><a href='stream_write_memory.html'>stream_write_memory</a></code>,
  <code><a href='stream_write_orc.html'>stream_write_orc</a></code>,
  <code><a href='stream_write_text.html'>stream_write_text</a></code></p></div>

    <h2 id="examples">Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><div class='input'><span class='kw'>if</span> (<span class='fl'>FALSE</span>) {

<span class='no'>sc</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='spark-connections.html'>spark_connect</a></span>(<span class='kw'>master</span> <span class='kw'>=</span> <span class='st'>"local"</span>)

<span class='fu'><a href='sdf_len.html'>sdf_len</a></span>(<span class='no'>sc</span>, <span class='fl'>10</span>) <span class='kw'>%&gt;%</span> <span class='fu'><a href='spark_write_parquet.html'>spark_write_parquet</a></span>(<span class='st'>"parquet-in"</span>)

<span class='no'>stream</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='stream_read_parquet.html'>stream_read_parquet</a></span>(<span class='no'>sc</span>, <span class='st'>"parquet-in"</span>) <span class='kw'>%&gt;%</span> <span class='fu'>stream_write_parquet</span>(<span class='st'>"parquet-out"</span>)

<span class='fu'><a href='stream_stop.html'>stream_stop</a></span>(<span class='no'>stream</span>)

}</div></code></pre></div>

    </div>

    </div>




