% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/data_interface.R
\name{spark_read_csv}
\alias{spark_read_csv}
\title{Read a CSV file into a Spark DataFrame}
\usage{
spark_read_csv(sc, name, path, header = TRUE, columns = NULL,
  infer_schema = TRUE, delimiter = ",", quote = "\\"", escape = "\\\\",
  charset = "UTF-8", null_value = NULL, options = list(),
  repartition = 0, memory = TRUE, overwrite = TRUE)
}
\arguments{
\item{sc}{A \code{spark_connection}.}

\item{name}{The name to assign to the newly generated table.}

\item{path}{The path to the file. Needs to be accessible from the cluster.
Supports the \samp{"hdfs://"}, \samp{"s3n://"} and \samp{"file://"} protocols.}

\item{header}{Boolean; should the first row of data be used as a header?
Defaults to \code{TRUE}.}

\item{columns}{A named vector specifying column types.}

\item{infer_schema}{Boolean; should column types be automatically inferred?
Requires one extra pass over the data. Defaults to \code{TRUE}.}

\item{delimiter}{The character used to delimit each column. Defaults to \samp{','}.}

\item{quote}{The character used as a quote. Defaults to \samp{'"'}.}

\item{escape}{The character used to escape other characters. Defaults to \samp{'\'}.}

\item{charset}{The character set. Defaults to \samp{"UTF-8"}.}

\item{null_value}{The character to use for null, or missing, values. Defaults to \code{NULL}.}

\item{options}{A list of strings with additional options.}

\item{repartition}{The number of partitions used to distribute the
generated table. Use 0 (the default) to avoid partitioning.}

\item{memory}{Boolean; should the data be loaded eagerly into memory? (That
is, should the table be cached?)}

\item{overwrite}{Boolean; overwrite the table with the given name if it
already exists?}
}
\description{
Read a tabular data file into a Spark DataFrame.
}
\details{
You can read data from HDFS (\code{hdfs://}), S3 (\code{s3n://}),
  as well as the local file system (\code{file://}).

If you are reading from a secure S3 bucket be sure that the
\code{AWS_ACCESS_KEY_ID} and \code{AWS_SECRET_ACCESS_KEY} environment
variables are both defined.

When \code{header} is \code{FALSE}, the column names are generated with a
\code{V} prefix; e.g. \code{V1, V2, ...}.
}
\seealso{
Other Spark serialization routines: \code{\link{spark_load_table}},
  \code{\link{spark_read_json}},
  \code{\link{spark_read_parquet}},
  \code{\link{spark_save_table}},
  \code{\link{spark_write_csv}},
  \code{\link{spark_write_json}},
  \code{\link{spark_write_parquet}}
}

