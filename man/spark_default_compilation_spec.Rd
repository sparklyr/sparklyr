% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spark_compile.R
\name{spark_default_compilation_spec}
\alias{spark_default_compilation_spec}
\title{Default Compilation Specification for Spark Extensions}
\usage{
spark_default_compilation_spec(pkg = infer_active_package_name(),
  locations = NULL)
}
\arguments{
\item{pkg}{The package containing Spark extensions to be compiled.}

\item{locations}{Additional locations to scan. By default, the
directories \code{/opt/scala} and \code{/usr/local/scala} will
be scanned.}
}
\description{
This is the default compilation specification used for
Spark extensions, when used with \code{\link{compile_package_jars}}.
}
