---
title: ""
menu:
  main:
    name: "Reference"
    weight: 100
---
    <h1 class = "content-header">Function Reference</h1>

    <div class="doc-page">

    <div class="doc-page-index">
    <ul data-gumshoe>
      <li><a href="#section-spark-operations">Spark Operations</a></li>
      <li><a href="#section-spark-data">Spark Data</a></li>
      <li><a href="#section-spark-tables">Spark Tables</a></li>
      <li><a href="#section-spark-dataframes">Spark DataFrames</a></li>
      <li><a href="#section-spark-machine-learning">Spark Machine Learning</a></li>
      <li><a href="#section-spark-feature-transformers">Spark Feature Transformers</a></li>
      <li><a href="#section-spark-machine-learning-utilities">Spark Machine Learning Utilities</a></li>
      <li><a href="#section-extensions">Extensions</a></li>
      <li><a href="#section-distributed-computing">Distributed Computing</a></li>
    </ul>
    </div>

    <div class="doc-page-body">

      <table class="ref-index">

      <colgroup>
        <col class="alias" />
        <col class="title" />
      </colgroup>

      <tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-operations" class="hasAnchor"><a href="#section-spark-operations" class="anchor"></a>Spark Operations</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="spark_config.html">spark_config</a></code> </p>
          </td>
          <td><p>Read Spark Configuration</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark-connections.html">spark_connect</a></code> <code><a href="spark-connections.html">spark_connection_is_open</a></code> <code><a href="spark-connections.html">spark_disconnect</a></code> <code><a href="spark-connections.html">spark_disconnect_all</a></code> </p>
          </td>
          <td><p>Manage Spark Connections</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_install.html">spark_install_find</a></code> <code><a href="spark_install.html">spark_install</a></code> <code><a href="spark_install.html">spark_uninstall</a></code> <code><a href="spark_install.html">spark_install_dir</a></code> <code><a href="spark_install.html">spark_install_tar</a></code> <code><a href="spark_install.html">spark_installed_versions</a></code> <code><a href="spark_install.html">spark_available_versions</a></code> </p>
          </td>
          <td><p>Find a given Spark installation by version.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_log.html">spark_log</a></code> </p>
          </td>
          <td><p>View Entries in the Spark Log</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_web.html">spark_web</a></code> </p>
          </td>
          <td><p>Open the Spark web interface</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-data" class="hasAnchor"><a href="#section-spark-data" class="anchor"></a>Spark Data</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_csv.html">spark_read_csv</a></code> </p>
          </td>
          <td><p>Read a CSV file into a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_jdbc.html">spark_read_jdbc</a></code> </p>
          </td>
          <td><p>Read from JDBC connection into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_json.html">spark_read_json</a></code> </p>
          </td>
          <td><p>Read a JSON file into a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_parquet.html">spark_read_parquet</a></code> </p>
          </td>
          <td><p>Read a Parquet file into a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_source.html">spark_read_source</a></code> </p>
          </td>
          <td><p>Read from a generic source into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_table.html">spark_read_table</a></code> </p>
          </td>
          <td><p>Reads from a Spark Table into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_csv.html">spark_write_csv</a></code> </p>
          </td>
          <td><p>Write a Spark DataFrame to a CSV</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_jdbc.html">spark_write_jdbc</a></code> </p>
          </td>
          <td><p>Writes a Spark DataFrame into a JDBC table</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_json.html">spark_write_json</a></code> </p>
          </td>
          <td><p>Write a Spark DataFrame to a JSON file</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_parquet.html">spark_write_parquet</a></code> </p>
          </td>
          <td><p>Write a Spark DataFrame to a Parquet file</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_source.html">spark_write_source</a></code> </p>
          </td>
          <td><p>Writes a Spark DataFrame into a generic source</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_table.html">spark_write_table</a></code> </p>
          </td>
          <td><p>Writes a Spark DataFrame into a Spark table</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-tables" class="hasAnchor"><a href="#section-spark-tables" class="anchor"></a>Spark Tables</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="src_databases.html">src_databases</a></code> </p>
          </td>
          <td><p>Show database list</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="tbl_cache.html">tbl_cache</a></code> </p>
          </td>
          <td><p>Cache a Spark Table</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="tbl_change_db.html">tbl_change_db</a></code> </p>
          </td>
          <td><p>Use specific database</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="tbl_uncache.html">tbl_uncache</a></code> </p>
          </td>
          <td><p>Uncache a Spark Table</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-dataframes" class="hasAnchor"><a href="#section-spark-dataframes" class="anchor"></a>Spark DataFrames</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_along.html">sdf_along</a></code> </p>
          </td>
          <td><p>Create DataFrame for along Object</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_bind.html">sdf_bind_rows</a></code> <code><a href="sdf_bind.html">sdf_bind_cols</a></code> </p>
          </td>
          <td><p>Bind multiple Spark DataFrames by row and column</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_broadcast.html">sdf_broadcast</a></code> </p>
          </td>
          <td><p>Broadcast hint</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_checkpoint.html">sdf_checkpoint</a></code> </p>
          </td>
          <td><p>Checkpoint a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_coalesce.html">sdf_coalesce</a></code> </p>
          </td>
          <td><p>Coalesces a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_copy_to.html">sdf_copy_to</a></code> <code><a href="sdf_copy_to.html">sdf_import</a></code> </p>
          </td>
          <td><p>Copy an Object into Spark</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_len.html">sdf_len</a></code> </p>
          </td>
          <td><p>Create DataFrame for Length</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_mutate.html">sdf_mutate</a></code> <code><a href="sdf_mutate.html">sdf_mutate_</a></code> </p>
          </td>
          <td><p>Mutate a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_num_partitions.html">sdf_num_partitions</a></code> </p>
          </td>
          <td><p>Gets number of partitions of a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_partition.html">sdf_partition</a></code> </p>
          </td>
          <td><p>Partition a Spark Dataframe</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_pivot.html">sdf_pivot</a></code> </p>
          </td>
          <td><p>Pivot a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf-transform-methods.html">sdf_predict</a></code> <code><a href="sdf-transform-methods.html">sdf_transform</a></code> <code><a href="sdf-transform-methods.html">sdf_fit</a></code> <code><a href="sdf-transform-methods.html">sdf_fit_and_transform</a></code> </p>
          </td>
          <td><p>Spark ML -- Transform, fit, and predict methods (sdf_ interface)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_read_column.html">sdf_read_column</a></code> </p>
          </td>
          <td><p>Read a Column from a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_register.html">sdf_register</a></code> </p>
          </td>
          <td><p>Register a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_repartition.html">sdf_repartition</a></code> </p>
          </td>
          <td><p>Repartition a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_residuals.html">sdf_residuals</a></code> </p>
          </td>
          <td><p>Model Residuals</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_sample.html">sdf_sample</a></code> </p>
          </td>
          <td><p>Randomly Sample Rows from a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_separate_column.html">sdf_separate_column</a></code> </p>
          </td>
          <td><p>Separate a Vector Column into Scalar Columns</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_seq.html">sdf_seq</a></code> </p>
          </td>
          <td><p>Create DataFrame for Range</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_sort.html">sdf_sort</a></code> </p>
          </td>
          <td><p>Sort a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_with_unique_id.html">sdf_with_unique_id</a></code> </p>
          </td>
          <td><p>Add a Unique ID Column to a Spark DataFrame</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-machine-learning" class="hasAnchor"><a href="#section-spark-machine-learning" class="anchor"></a>Spark Machine Learning</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="ml_als.html">ml_als</a></code> <code><a href="ml_als.html">ml_recommend</a></code> <code><a href="ml_als.html">ml_als_factorization</a></code> </p>
          </td>
          <td><p>Spark ML -- ALS</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_decision_tree.html">ml_decision_tree_classifier</a></code> <code><a href="ml_decision_tree.html">ml_decision_tree</a></code> <code><a href="ml_decision_tree.html">ml_decision_tree_regressor</a></code> </p>
          </td>
          <td><p>Spark ML -- Decision Trees</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_generalized_linear_regression.html">ml_generalized_linear_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Generalized Linear Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_gradient_boosted_trees.html">ml_gbt_classifier</a></code> <code><a href="ml_gradient_boosted_trees.html">ml_gradient_boosted_trees</a></code> <code><a href="ml_gradient_boosted_trees.html">ml_gbt_regressor</a></code> </p>
          </td>
          <td><p>Spark ML -- Gradient Boosted Trees</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_kmeans.html">ml_kmeans</a></code> <code><a href="ml_kmeans.html">ml_compute_cost</a></code> </p>
          </td>
          <td><p>Spark ML -- K-Means Clustering</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_lda.html">ml_lda</a></code> <code><a href="ml_lda.html">ml_describe_topics</a></code> <code><a href="ml_lda.html">ml_log_likelihood</a></code> <code><a href="ml_lda.html">ml_log_perplexity</a></code> </p>
          </td>
          <td><p>Spark ML -- Latent Dirichlet Allocation</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_linear_regression.html">ml_linear_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Linear Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_logistic_regression.html">ml_logistic_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Logistic Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_model_data.html">ml_model_data</a></code> </p>
          </td>
          <td><p>Extracts data associated with a Spark ML model</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_multilayer_perceptron_classifier.html">ml_multilayer_perceptron_classifier</a></code> <code><a href="ml_multilayer_perceptron_classifier.html">ml_multilayer_perceptron</a></code> </p>
          </td>
          <td><p>Spark ML -- Multilayer Perceptron</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_naive_bayes.html">ml_naive_bayes</a></code> </p>
          </td>
          <td><p>Spark ML -- Naive-Bayes</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_one_vs_rest.html">ml_one_vs_rest</a></code> </p>
          </td>
          <td><p>Spark ML -- OneVsRest</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_pca.html">ft_pca</a></code> <code><a href="ft_pca.html">ml_pca</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- PCA (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_random_forest.html">ml_random_forest_classifier</a></code> <code><a href="ml_random_forest.html">ml_random_forest</a></code> <code><a href="ml_random_forest.html">ml_random_forest_regressor</a></code> </p>
          </td>
          <td><p>Spark ML -- Random Forest</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_aft_survival_regression.html">ml_aft_survival_regression</a></code> <code><a href="ml_aft_survival_regression.html">ml_survival_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Survival Regression</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-feature-transformers" class="hasAnchor"><a href="#section-spark-feature-transformers" class="anchor"></a>Spark Feature Transformers</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="ft_binarizer.html">ft_binarizer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- Binarizer (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_bucketizer.html">ft_bucketizer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- Bucketizer (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_count_vectorizer.html">ft_count_vectorizer</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- CountVectorizer (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_dct.html">ft_dct</a></code> <code><a href="ft_dct.html">ft_discrete_cosine_transform</a></code> </p>
          </td>
          <td><p>Feature Transformation -- Discrete Cosine Transform (DCT) (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_elementwise_product.html">ft_elementwise_product</a></code> </p>
          </td>
          <td><p>Feature Transformation -- ElementwiseProduct (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_index_to_string.html">ft_index_to_string</a></code> </p>
          </td>
          <td><p>Feature Transformation -- IndexToString (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_one_hot_encoder.html">ft_one_hot_encoder</a></code> </p>
          </td>
          <td><p>Feature Transformation -- OneHotEncoder (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_quantile_discretizer.html">ft_quantile_discretizer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- QuantileDiscretizer (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sql-transformer.html">ft_sql_transformer</a></code> <code><a href="sql-transformer.html">ft_dplyr_transformer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- SQLTransformer</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_string_indexer.html">ft_string_indexer</a></code> <code><a href="ft_string_indexer.html">ml_labels</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- StringIndexer (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_vector_assembler.html">ft_vector_assembler</a></code> </p>
          </td>
          <td><p>Feature Transformation -- VectorAssembler (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_tokenizer.html">ft_tokenizer</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- Tokenizer (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_regex_tokenizer.html">ft_regex_tokenizer</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- RegexTokenizer (Transformer)</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-machine-learning-utilities" class="hasAnchor"><a href="#section-spark-machine-learning-utilities" class="anchor"></a>Spark Machine Learning Utilities</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="ml_evaluator.html">ml_binary_classification_evaluator</a></code> <code><a href="ml_evaluator.html">ml_binary_classification_eval</a></code> <code><a href="ml_evaluator.html">ml_multiclass_classification_evaluator</a></code> <code><a href="ml_evaluator.html">ml_classification_eval</a></code> <code><a href="ml_evaluator.html">ml_regression_evaluator</a></code> </p>
          </td>
          <td><p>Spark ML - Evaluators</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_tree_feature_importance.html">ml_tree_feature_importance</a></code> </p>
          </td>
          <td><p>Spark ML - Feature Importance for Tree Models</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-extensions" class="hasAnchor"><a href="#section-extensions" class="anchor"></a>Extensions</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="compile_package_jars.html">compile_package_jars</a></code> </p>
          </td>
          <td><p>Compile Scala sources into a Java Archive (jar)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="connection_config.html">connection_config</a></code> </p>
          </td>
          <td><p>Read configuration values for a connection</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="download_scalac.html">download_scalac</a></code> </p>
          </td>
          <td><p>Downloads default Scala Compilers</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="find_scalac.html">find_scalac</a></code> </p>
          </td>
          <td><p>Discover the Scala Compiler</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark-api.html">spark_context</a></code> <code><a href="spark-api.html">java_context</a></code> <code><a href="spark-api.html">hive_context</a></code> <code><a href="spark-api.html">spark_session</a></code> </p>
          </td>
          <td><p>Access the Spark API</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="hive_context_config.html">hive_context_config</a></code> </p>
          </td>
          <td><p>Runtime configuration interface for Hive</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="invoke.html">invoke</a></code> <code><a href="invoke.html">invoke_static</a></code> <code><a href="invoke.html">invoke_new</a></code> </p>
          </td>
          <td><p>Invoke a Method on a JVM Object</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="register_extension.html">register_extension</a></code> <code><a href="register_extension.html">registered_extensions</a></code> </p>
          </td>
          <td><p>Register a Package that Implements a Spark Extension</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_compilation_spec.html">spark_compilation_spec</a></code> </p>
          </td>
          <td><p>Define a Spark Compilation Specification</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_default_compilation_spec.html">spark_default_compilation_spec</a></code> </p>
          </td>
          <td><p>Default Compilation Specification for Spark Extensions</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_connection.html">spark_connection</a></code> </p>
          </td>
          <td><p>Retrieve the Spark Connection Associated with an R Object</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_context_config.html">spark_context_config</a></code> </p>
          </td>
          <td><p>Runtime configuration interface for Spark.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_dataframe.html">spark_dataframe</a></code> </p>
          </td>
          <td><p>Retrieve a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_dependency.html">spark_dependency</a></code> </p>
          </td>
          <td><p>Define a Spark dependency</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_home_set.html">spark_home_set</a></code> </p>
          </td>
          <td><p>Set the SPARK_HOME environment variable</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_jobj.html">spark_jobj</a></code> </p>
          </td>
          <td><p>Retrieve a Spark JVM Object Reference</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_version.html">spark_version</a></code> </p>
          </td>
          <td><p>Get the Spark Version Associated with a Spark Connection</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-distributed-computing" class="hasAnchor"><a href="#section-distributed-computing" class="anchor"></a>Distributed Computing</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="spark_apply.html">spark_apply</a></code> </p>
          </td>
          <td><p>Apply an R Function in Spark</p></td>
        </tr>
      </tbody>
      </table>

  </div>

  </div>



